<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>KSML Configuration Reference - KSML Documentation</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/fontawesome.min.css" rel="stylesheet">
        <link href="../../css/brands.min.css" rel="stylesheet">
        <link href="../../css/solid.min.css" rel="stylesheet">
        <link href="../../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../..">KSML Documentation</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item">
                                <a href="../.." class="nav-link">Home</a>
                            </li>
                            <li class="nav-item">
                                <a href="../../tutorials/getting-started/" class="nav-link">Getting Started</a>
                            </li>
                            <li class="nav-item">
                                <a href="../../core-concepts/" class="nav-link">Core Concepts</a>
                            </li>
                            <li class="nav-item">
                                <a href="../../tutorials/" class="nav-link">Tutorials</a>
                            </li>
                            <li class="nav-item">
                                <a href="../../use-cases/" class="nav-link">Use Case Guides</a>
                            </li>
                            <li class="nav-item">
                                <a href="../" class="nav-link">Reference</a>
                            </li>
                            <li class="nav-item">
                                <a href="../../resources/" class="nav-link">Resources</a>
                            </li>
                            <li class="nav-item">
                                <a href="../../about/" class="nav-link">About</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#ksml-configuration-reference" class="nav-link">KSML Configuration Reference</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#ksml-configuration-file-structure" class="nav-link">KSML Configuration File Structure</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#how-to-configure-notations" class="nav-link">How to configure notations</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#list-of-available-supported-variations" class="nav-link">List of available supported variations</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#application-metadata" class="nav-link">Application Metadata</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#data-definitions" class="nav-link">Data Definitions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#function-definitions" class="nav-link">Function Definitions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#pipeline-definitions" class="nav-link">Pipeline Definitions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#application-configuration" class="nav-link">Application Configuration</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#advanced-configuration" class="nav-link">Advanced Configuration</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#best-practices" class="nav-link">Best Practices</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#related-topics" class="nav-link">Related Topics</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="ksml-configuration-reference">KSML Configuration Reference</h1>
<p>This document provides a comprehensive reference for all configuration options available in KSML. Each configuration
section is described with its purpose, available options, and examples.</p>
<h2 id="ksml-configuration-file-structure">KSML Configuration File Structure</h2>
<p>The KSML configuration is usually stored in a file called <code>ksml-runner.yaml</code>. It contains the following main sections:</p>
<pre><code class="language-yaml">ksml:
  # Configuration related to KSML itself

kafka:
  # Configuration required to connect to Kafka
</code></pre>
<p>The <code>ksml</code> section contains all configuration that KSML needs to understand what it needs to do. The <code>kafka</code> section
contains the relevant configuration to connect to allow Kafka Streams to connect to Kafka. All the normal Kafka Streams
connection properties can be configured here.</p>
<h3 id="template-ksml-runneryaml">Template <code>ksml-runner.yaml</code></h3>
<p>Below is a template <code>ksml-runner.yaml</code> that you can copy-paste for your own setup and fill out with your own relevant
configuration. The entries are explained in the next sections.</p>
<pre><code class="language-yaml">ksml:
  # The examples directory is mounted to /ksml in the Docker container
  configDirectory: .                 # When not set defaults to the working directory
  schemaDirectory: .                 # When not set defaults to the config directory
  storageDirectory: /tmp             # When not set defaults to the default JVM temp directory

  # This section defines if a REST endpoint is opened on the KSML runner, through which
  # state stores and/or readiness / liveness probes can be accessed.
  applicationServer:
    enabled: false                   # Set to true to enable, or false to disable
    host: 0.0.0.0                    # IP address to bind the REST server to
    port: 8080                       # Port number to listen on

  # This section defines whether a Prometheus endpoint is opened to allow metric scraping.
  prometheus:
    enabled: false                   # Set to true to enable, or false to disable
    host: 0.0.0.0                    # IP address to bind the Prometheus agent server to
    port: 9999                       # Port number to listen on

  # This section enables error handling or error ignoring for certain types of errors.
  errorHandling:
    consume:                         # Error handling definitions for consume errors
      log: true                      # Log errors true/false
      logPayload: true               # Upon error, should the payload of the message be dumped to the log file.
      loggerName: ConsumeError       # Definition of the error logger name.
      handler: stopOnFail            # How to proceed after encountering the error. Either continueOnFail or stopOnFail.
    process:
      log: true                      # Log errors true/false
      logPayload: true               # Upon error, should the payload of the message be dumped to the log file.
      loggerName: ProcessError       # Definition of the error logger name.
      handler: continueOnFail        # How to proceed after encountering the error. Either continueOnFail or stopOnFail.
    produce:
      log: true                      # Log errors true/false
      logPayload: true               # Upon error, should the payload of the message be dumped to the log file.
      loggerName: ProduceError       # Definition of the error logger name.
      handler: continueOnFail        # How to proceed after encountering the error. Either continueOnFail or stopOnFail.

  enableProducers: true              # Set to true to allow producer definitions to be parsed in the KSML definitions and be executed.
  enablePipelines: false             # Set to true to allow pipeline definitions to be parsed in the KSML definitions and be executed.

  # This section tells KSML which schema registries are available
  schemaRegistries:
    # Definition of an Apicurio schema registry
    apicurio:
      config:
        # Below is an example SSL configuration for Apicurio Serialization library from Apicurio documentation
        # apicurio.registry.request.ssl.keystore.location: /path/to/keystore.jks
        # apicurio.registry.request.ssl.keystore.type: JKS
        # apicurio.registry.request.ssl.keystore.password: password
        # apicurio.registry.request.ssl.key.password: password
        # apicurio.registry.request.ssl.truststore.location: /path/to/truststore.jks
        # apicurio.registry.request.ssl.truststore.type: JKS
        # apicurio.registry.request.ssl.truststore.password: password

    # Definition of a Confluent schema registry
    confluent:
      config:
        # Example SSL configuration for Confluent schema registry
        # schema.registry.ssl.protocol: TLSv1.3
        # schema.registry.ssl.enabled.protocols: TLSv1.3,TLSv1.2
        # schema.registry.ssl.endpoint.identification.algorithm: &quot;&quot;
        # schema.registry.ssl.keystore.location: /path/to/keystore.jks
        # schema.registry.ssl.keystore.type: JKS
        # schema.registry.ssl.key.password: password
        # schema.registry.ssl.keystore.password: password
        # schema.registry.ssl.truststore.location: /path/to/truststore.jks
        # schema.registry.ssl.truststore.type: JKS
        # schema.registry.ssl.truststore.password: password

  # This section tells KSML which serializers / deserializers handle which notation types
  notations:
    # Definition for &quot;avro&quot; notation
    avro:
      serde: confluent_avro          # For AVRO there are two implementations: apicurio_avro and confluent_avro
      schemaRegistry: confluent
      config:
        # Specify all properties to be passed into Confluent's KafkaAvroSerializer and KafkaAvroDeserializer
        normalize.schemas: true
        auto.register.schemas: false

    # Definition for &quot;second_avro&quot; notation. With this entry, you can use a type like &quot;second_avro:SchemaName&quot; in your
    # KSML definition, which then uses the Apicurio implementation for AVRO.
    second_avro:
      serde: apicurio_avro           # For AVRO there are two implementations: apicurio_avro and confluent_avro
      schemaRegistry: apicurio
      config:
        # Specify all properties to be passed into Apicurio's AvroKafkaSerializer and AvroKafkaDeserializer
        # apicurio.registry.avro.encoding: &quot;BINARY&quot;
        # apicurio.registry.headers.enabled: &quot;true&quot;
        # apicurio.registry.serde.IdHandler: &quot;io.apicurio.registry.serde.Default4ByteIdHandler&quot;
        # apicurio.registry.schema-resolver: &quot;io.apicurio.registry.resolver.DefaultSchemaResolver&quot;

    # Definition for &quot;jsonschema&quot; notation
    jsonschema:
      serde: apicurio_jsonschema     # For JSON Schema there are two implementations: apicurio_jsonschema and confluent_jsonschema
      schemaRegistry: apicurio
      config:
        # Specify all properties to be passed into Apicurio's JsonSchemaKafkaSerializer and JsonSchemaKafkaDeserializer
        apicurio.registry.auto-register: true

    # Definition for &quot;protobuf&quot; notation
    protobuf:                        # Definition for &quot;protobuf&quot; notation
      serde: apicurio_protobuf       # For Protobuf there are two implementations: apicurio_protobuf and confluent_protobuf
      schemaRegistry: apicurio
      config:
        # Specify all properties to be passed into Apicurio's ProtobufKafkaSerializer and ProtobufKafkaDeserializer
        apicurio.registry.auto-register: false

  # Section where you specify which KSML definitions to load, parse and execute.
  definitions:
    # Format is &lt;namespace&gt;: &lt;ksml_definition_filename&gt;
    generate_alert_setting: 00-example-generate-alertsettings.yaml
    generate_sensor_data_avro: 00-example-generate-sensordata-avro.yaml
    # generate_sensor_data_avro_batch: 00-example-generate-sensordata-avro-batch.yaml
    # generate_sensor_data_binary: 00-example-generate-sensordata-binary.yaml
    # generate_sensor_data_protobuf: 00-example-generate-sensordata-protobuf.yaml

    inspect: 01-example-inspect.yaml
    copy: 02-example-copy.yaml
    filter: 03-example-filter.yaml
    # branch: 04-example-branch.yaml
    # route: 05-example-route.yaml
    # duplicate: 06-example-duplicate.yaml
    # convert: 07-example-convert.yaml
    # count: 08-example-count.yaml
    # aggregate: 09-example-aggregate.yaml
    # queryable_table: 10-example-queryable-table.yaml
    # field_modification: 11-example-field-modification.yaml
    # byte_manipulation: 12-example-byte-manipulation.yaml
    # join: 13-example-join.yaml
    # manual_state_store: 14-example-manual-state-store.yaml
    # pipeline_linking: 15-example-pipeline-linking.yaml
    # transform_metadata: 16-example-transform-metadata.yaml
    # inspect_with_metrics: 17-example-inspect-with-metrics.yaml
    # timestamp_extractor: 18-example-timestamp-extractor.yaml
    # performance-measurement: 19-example-performance-measurement.yaml

# This setup connects to the Kafka broker and schema registry started with the example docker-compose file
# These examples are intended to run from inside a container on the same network
kafka:
  bootstrap.servers: broker:9093
  application.id: io.ksml.example.producer
  security.protocol: PLAINTEXT
  acks: all

  # These are Kafka SSL configuration properties. Check the documentation at1
  # Check the documentation at https://kafka.apache.org/documentation/#producerconfigs for more properties
  # security.protocol: SSL
  # ssl.protocol: TLSv1.3
  # ssl.enabled.protocols: TLSv1.3,TLSv1.2
  # ssl.endpoint.identification.algorithm: &quot;&quot;
  # ssl.keystore.type: JKS
  # ssl.truststore.type: JKS
  # ssl.key.password: xxx
  # ssl.keystore.password: xxx
  # ssl.keystore.location: /path/to/ksml.keystore.jks
  # ssl.truststore.password: xxx
  # ssl.truststore.location: /path/to/ksml.truststore.jks

  # Use these configuration properties when connecting to a cluster using the Axual naming patterns.
  # These patterns are resolved into the actual name used on Kafka using the values in this configuration map
  # and the topic names specified in the definition YAML files
  # The pattern below results in Kafka topic ksmldemo-dta-dev-&lt;topic name from KSML definition YAML&gt;
  # axual.topic.pattern: &quot;{tenant}-{instance}-{environment}-{topic}&quot;
  # axual.group.id.pattern: &quot;{tenant}-{instance}-{environment}-{group.id}&quot;
  # axual.transactional.id.pattern: &quot;{tenant}-{instance}-{environment}-{transactional.id}&quot;
  # tenant: &quot;ksmldemo&quot;
  # instance: &quot;dta&quot;
  # environment: &quot;dev&quot;
</code></pre>
<h3 id="ksml-configuration">KSML Configuration</h3>
<p>The <code>ksml</code> section in the configuration contains the following items:</p>
<pre><code class="language-yaml">ksml:
  # The examples directory is mounted to /ksml in the Docker container
  configDirectory: .              # When not set defaults to the working directory
  schemaDirectory: .              # When not set defaults to the config directory
  storageDirectory: /tmp          # When not set defaults to the default JVM temp directory
  createStorageDirectory: false   # When set to true, the storage directory will be created if it does not exist

  # This section defines if a REST endpoint is opened on the KSML runner, through which
  # state stores and/or readiness / liveness probes can be accessed.
  applicationServer:
    enabled: false                # Set to true to enable, or false to disable
    host: 0.0.0.0                 # IP address to bind the REST server to
    port: 8080                    # Port number to listen on

  # This section defines whether a Prometheus endpoint is opened to allow metric scraping.
  prometheus:
    enabled: true                 # Set to true to enable, or false to disable
    host: 0.0.0.0                 # IP address to bind the Prometheus agent server to
    port: 9999                    # Port number to listen on

  # This section enables error handling or error ignoring for certain types of errors.
  errorHandling:
    consume:                      # Error handling definitions for consume errors
      log: true                   # Log errors true/false
      logPayload: true            # Upon error, should the payload of the message be dumped to the log file.
      loggerName: ConsumeError    # Definition of the error logger name.
      handler: stopOnFail         # How to proceed after encountering the error. Either continueOnFail or stopOnFail.
    process:
      log: true                   # Log errors true/false
      logPayload: true            # Upon error, should the payload of the message be dumped to the log file.
      loggerName: ProcessError    # Definition of the error logger name.
      handler: stopOnFail     # How to proceed after encountering the error. Either continueOnFail or stopOnFail.
    produce:
      log: true                   # Log errors true/false
      logPayload: true            # Upon error, should the payload of the message be dumped to the log file.
      loggerName: ProduceError    # Definition of the error logger name.
      handler: continueOnFail     # How to proceed after encountering the error. Either continueOnFail or stopOnFail.

  enableProducers: true           # Set to true to allow producer definitions to be parsed in the KSML definitions and be executed.
  enablePipelines: true           # Set to true to allow pipeline definitions to be parsed in the KSML definitions and be executed.

   # This section tells KSML which schema registries are available
  schemaRegistries:
     # Definition of an Apicurio schema registry
     apicurio:
        config:
        # Below is an example SSL configuration for Apicurio Serialization library from Apicurio documentation
        # apicurio.registry.request.ssl.keystore.location: /path/to/keystore.jks
        # apicurio.registry.request.ssl.keystore.type: JKS
        # apicurio.registry.request.ssl.keystore.password: password
        # apicurio.registry.request.ssl.key.password: password
        # apicurio.registry.request.ssl.truststore.location: /path/to/truststore.jks
        # apicurio.registry.request.ssl.truststore.type: JKS
        # apicurio.registry.request.ssl.truststore.password: password

     # Definition of a Confluent schema registry
     confluent:
        config:
        # Example SSL configuration for Confluent schema registry
        # schema.registry.ssl.protocol: TLSv1.3
        # schema.registry.ssl.enabled.protocols: TLSv1.3,TLSv1.2
        # schema.registry.ssl.endpoint.identification.algorithm: &quot;&quot;
        # schema.registry.ssl.keystore.location: /path/to/keystore.jks
        # schema.registry.ssl.keystore.type: JKS
        # schema.registry.ssl.key.password: password
        # schema.registry.ssl.keystore.password: password
        # schema.registry.ssl.truststore.location: /path/to/truststore.jks
        # schema.registry.ssl.truststore.type: JKS
        # schema.registry.ssl.truststore.password: password

   # This section tells KSML which serializers / deserializers handle which notation types
  notations:
     # Definition for &quot;avro&quot; notation
     avro:
        serde: confluent_avro         # For AVRO there are two implementations: apicurio_avro and confluent_avro
        schemaRegistry: confluent
        config:
           # Specify all properties to be passed into Confluent's KafkaAvroSerializer and KafkaAvroDeserializer
           normalize.schemas: true
           auto.register.schemas: false

     # Definition for &quot;second_avro&quot; notation. With this entry, you can use a type like &quot;second_avro:SchemaName&quot; in your
     # KSML definition, which then uses the Apicurio implementation for AVRO.
     second_avro:
        serde: apicurio_avro
        schemaRegistry: apicurio
        config:
        # Apicurio Avro serialisation settings
        # apicurio.registry.avro.encoding: &quot;BINARY&quot;
        # apicurio.registry.headers.enabled: &quot;true&quot;
        # apicurio.registry.serde.IdHandler: &quot;io.apicurio.registry.serde.Default4ByteIdHandler&quot;
        # apicurio.registry.schema-resolver: &quot;io.apicurio.registry.resolver.DefaultSchemaResolver&quot;

     # Definition for &quot;json&quot; notation
     jsonschema:
        serde: apicurio_json          # For JSON there is only one implementation: apicurio_json
        schemaRegistry: apicurio
        config:
           apicurio.registry.auto-register: true

     # Definition for &quot;protobuf&quot; notation
     protobuf:                      # Definition for &quot;protobuf&quot; notation
        type: apicurio_protobuf      # For Protobuf there is only one implementation: apicurio_protobuf
        schemaRegistry: apicurio
        ## Below this line, specify properties to be passed into Apicurio's ProtobufKafkaSerializer and ProtobufKafkaDeserializer
        config:
           apicurio.registry.auto-register: false

  # Section where you specify which KSML definitions to load, parse and execute.
  definitions:
    # Format is &lt;namespace&gt;: &lt;ksml_definition_filename&gt;
    inspect: 01-example-inspect.yaml
#    copy: 02-example-copy.yaml
#    filter: 03-example-filter.yaml
#    branch: 04-example-branch.yaml
#    route: 05-example-route.yaml
#    duplicate: 06-example-duplicate.yaml
#    convert: 07-example-convert.yaml
#    count: 08-example-count.yaml
#    aggregate: 09-example-aggregate.yaml
#    queryable_table: 10-example-queryable-table.yaml
#    field_modification: 11-example-field-modification.yaml
#    byte_manipulation: 12-example-byte-manipulation.yaml
#    join: 13-example-join.yaml
#    manual_state_store: 14-example-manual-state-store.yaml
#    pipeline_linking: 15-example-pipeline-linking.yaml
#    transform_metadata: 16-example-transform-metadata.yaml
#    inspect_with_metrics: 17-example-inspect-with-metrics.yaml
#    timestamp_extractor: 18-example-timestamp-extractor.yaml
#    performance-measurement: 19-example-performance-measurement.yaml

# This setup connects to the Kafka broker and schema registry started with the example docker-compose file
# These examples are intended to run from a inside a container on the same network
kafka:
  application.id: io.ksml.example.streaming
  # The group instance id is used to identify a single instance of the application, allowing for
  # faster rebalances and less partition reassignments. The name must be unique for each member in the group.
  group.instance.id: example-instance

  bootstrap.servers: broker:9093
  security.protocol: PLAINTEXT
  auto.offset.reset: earliest
  acks: all

  # These are Kafka SSL configuration properties. Check the documentation at1
  # Check the documentation at https://kafka.apache.org/documentation/#producerconfigs for more properties

  #  security.protocol: SSL
  #  ssl.protocol: TLSv1.3
  #  ssl.enabled.protocols: TLSv1.3,TLSv1.2
  #  ssl.endpoint.identification.algorithm: &quot;&quot;
  #  ssl.keystore.type: JKS
  #  ssl.truststore.type: JKS
  #  ssl.key.password: xxx
  #  ssl.keystore.password: xxx
  #  ssl.keystore.location: /path/to/ksml.keystore.jks
  #  ssl.truststore.password: xxx
  #  ssl.truststore.location: /path/to/ksml.truststore.jks

  # Use these configuration properties when connecting to a cluster using the Axual naming patterns.
  # These patterns are resolved into the actual name used on Kafka using the values in this configuration map
  # and the topic names specified in the definition YAML files

  #  axual.topic.pattern: &quot;{tenant}-{instance}-{environment}-{topic}&quot;
  #  # Results in Kafka topic ksmldemo-dta-dev-&lt;topic name from KSML definition YAML&gt;
  #  axual.group.id.pattern: &quot;{tenant}-{instance}-{environment}-{group.id}&quot;
  #  axual.transactional.id.pattern: &quot;{tenant}-{instance}-{environment}-{transactional.id}&quot;
  #  tenant: &quot;ksmldemo&quot;
  #  instance: &quot;dta&quot;
  #  environment: &quot;dev&quot;
</code></pre>
<h3 id="kafka-configuration">Kafka Configuration</h3>
<p>A KSML configuration file typically consists of the following main sections:</p>
<pre><code class="language-yaml"># Basic metadata
name: &quot;my-ksml-application&quot;
version: &quot;1.0.0&quot;
description: &quot;My KSML Application&quot;

# Data definitions
streams:
# Stream definitions
tables:
# Table definitions
globalTables:
# Global table definitions

# Function definitions
functions:
# Function definitions

# Pipeline definitions
pipelines:
# Pipeline definitions

# Application configuration
config:
# Application configuration
</code></pre>
<h2 id="how-to-configure-notations">How to configure notations</h2>
<p>To accommodate for variations in Kafka setups and/or ecosystem variations, the following table lists the available
options you can configure. The <code>notation name</code> lists the notation you use in your KSML definitions, for example
<code>avro:SensorData</code>. The configuration of all notations is done in the <code>ksml-runner.yaml</code> file, from which KSML reads its
technical configuration parameters.</p>
<h2 id="list-of-available-supported-variations">List of available supported variations</h2>
<p>The table below provides a complete list of all notations, their possible implementation alternatives and corresponding
characteristics, such as what data types a notation maps to.</p>
<table>
<thead>
<tr>
<th>Notation name</th>
<th>Available serdes</th>
<th style="text-align: center;">Serde supplier</th>
<th style="text-align: center;">Schema Registry</th>
<th style="text-align: center;">Loaded in KSML</th>
<th>Remarks</th>
</tr>
</thead>
<tbody>
<tr>
<td>avro</td>
<td>apicurio_avro</td>
<td style="text-align: center;">Apicurio</td>
<td style="text-align: center;">Apicurio</td>
<td style="text-align: center;">If configured</td>
<td>Talks to Apicurio Schema Registry</td>
</tr>
<tr>
<td>avro</td>
<td>confluent_avro</td>
<td style="text-align: center;">Confluent</td>
<td style="text-align: center;">Confluent</td>
<td style="text-align: center;">Default</td>
<td>Talks to Confluent Schema Registry</td>
</tr>
<tr>
<td>csv</td>
<td>csv</td>
<td style="text-align: center;">ksml</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">Always</td>
<td>CSV Schemaless</td>
</tr>
<tr>
<td>json</td>
<td>json</td>
<td style="text-align: center;">ksml</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">Always</td>
<td>JSON Schemaless</td>
</tr>
<tr>
<td>jsonschema</td>
<td>apicurio_jsonschema</td>
<td style="text-align: center;">Apicurio</td>
<td style="text-align: center;">Apicurio</td>
<td style="text-align: center;">If configured</td>
<td>Talks to Apicurio Schema Registry</td>
</tr>
<tr>
<td>jsonschema</td>
<td>confluent_jsonschema</td>
<td style="text-align: center;">Confluent</td>
<td style="text-align: center;">Confluent</td>
<td style="text-align: center;">If configured</td>
<td>Talks to Confluent Schema Registry</td>
</tr>
<tr>
<td>protobuf</td>
<td>apicurio_protobuf</td>
<td style="text-align: center;">Apicurio</td>
<td style="text-align: center;">Y</td>
<td style="text-align: center;">If configured</td>
<td>Any Protobuf, schema loaded from SR upon consume</td>
</tr>
<tr>
<td>protobuf</td>
<td>confluent_protobuf</td>
<td style="text-align: center;">Confluent</td>
<td style="text-align: center;">Y</td>
<td style="text-align: center;">If configured</td>
<td>Any Protobuf, schema loaded from SR upon consume</td>
</tr>
<tr>
<td>soap</td>
<td>soap</td>
<td style="text-align: center;">ksml</td>
<td style="text-align: center;">N</td>
<td style="text-align: center;">Always</td>
<td>SOAP Schemaless</td>
</tr>
<tr>
<td>xml</td>
<td>xml</td>
<td style="text-align: center;">ksml</td>
<td style="text-align: center;">N</td>
<td style="text-align: center;">Always</td>
<td>XML Schemaless</td>
</tr>
</tbody>
</table>
<h2 id="application-metadata">Application Metadata</h2>
<h3 id="basic-metadata">Basic Metadata</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>name</code></td>
<td>String</td>
<td>Yes</td>
<td>The name of the KSML definition</td>
</tr>
<tr>
<td><code>version</code></td>
<td>String</td>
<td>No</td>
<td>The version of the KSML definition</td>
</tr>
<tr>
<td><code>description</code></td>
<td>String</td>
<td>No</td>
<td>A description of the KSML definition</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">name: &quot;order-processing-app&quot;
version: &quot;1.2.3&quot;
description: &quot;Processes orders from the order topic and enriches them with customer data&quot;
</code></pre>
<h2 id="data-definitions">Data Definitions</h2>
<h3 id="streams">Streams</h3>
<p>Streams represent unbounded sequences of records.</p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>topic</code></td>
<td>String</td>
<td>Yes</td>
<td>The Kafka topic to read from or write to</td>
</tr>
<tr>
<td><code>keyType</code></td>
<td>String</td>
<td>Yes</td>
<td>The type of the record key</td>
</tr>
<tr>
<td><code>valueType</code></td>
<td>String</td>
<td>Yes</td>
<td>The type of the record value</td>
</tr>
<tr>
<td><code>offsetResetPolicy</code></td>
<td>String</td>
<td>No</td>
<td>The offset reset policy (<code>earliest</code>, <code>latest</code>, <code>none</code>)</td>
</tr>
<tr>
<td><code>timestampExtractor</code></td>
<td>String</td>
<td>No</td>
<td>The function to extract timestamps from records</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">streams:
  orders:
    topic: &quot;orders&quot;
    keyType: &quot;string&quot;
    valueType: &quot;avro:Order&quot;
    offsetResetPolicy: &quot;earliest&quot;
</code></pre>
<h3 id="tables">Tables</h3>
<p>Tables represent changelog streams from a primary-keyed table.</p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>topic</code></td>
<td>String</td>
<td>Yes</td>
<td>The Kafka topic to read from or write to</td>
</tr>
<tr>
<td><code>keyType</code></td>
<td>String</td>
<td>Yes</td>
<td>The type of the record key</td>
</tr>
<tr>
<td><code>valueType</code></td>
<td>String</td>
<td>Yes</td>
<td>The type of the record value</td>
</tr>
<tr>
<td><code>offsetResetPolicy</code></td>
<td>String</td>
<td>No</td>
<td>The offset reset policy (<code>earliest</code>, <code>latest</code>, <code>none</code>)</td>
</tr>
<tr>
<td><code>timestampExtractor</code></td>
<td>String</td>
<td>No</td>
<td>The function to extract timestamps from records</td>
</tr>
<tr>
<td><code>store</code></td>
<td>String</td>
<td>No</td>
<td>The name of the key/value state store to use</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">tables:
  customers:
    topic: &quot;customers&quot;
    keyType: &quot;string&quot;
    valueType: &quot;avro:Customer&quot;
    store: &quot;customer-store&quot;
</code></pre>
<h3 id="global-tables">Global Tables</h3>
<p>Global tables are similar to tables but are fully replicated on each instance of the application.</p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>topic</code></td>
<td>String</td>
<td>Yes</td>
<td>The Kafka topic to read from</td>
</tr>
<tr>
<td><code>keyType</code></td>
<td>String</td>
<td>Yes</td>
<td>The type of the record key</td>
</tr>
<tr>
<td><code>valueType</code></td>
<td>String</td>
<td>Yes</td>
<td>The type of the record value</td>
</tr>
<tr>
<td><code>offsetResetPolicy</code></td>
<td>String</td>
<td>No</td>
<td>The offset reset policy (<code>earliest</code>, <code>latest</code>, <code>none</code>)</td>
</tr>
<tr>
<td><code>timestampExtractor</code></td>
<td>String</td>
<td>No</td>
<td>The function to extract timestamps from records</td>
</tr>
<tr>
<td><code>store</code></td>
<td>String</td>
<td>No</td>
<td>The name of the key/value state store to use</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">globalTables:
  products:
    topic: &quot;products&quot;
    keyType: &quot;string&quot;
    valueType: &quot;avro:Product&quot;
</code></pre>
<h2 id="function-definitions">Function Definitions</h2>
<p>Functions define reusable pieces of logic that can be referenced in pipelines.</p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>type</code></td>
<td>String</td>
<td>Yes</td>
<td>The type of function (predicate, mapper, aggregator, etc.)</td>
</tr>
<tr>
<td><code>expression</code></td>
<td>String</td>
<td>No</td>
<td>A simple expression for the function</td>
</tr>
<tr>
<td><code>code</code></td>
<td>String</td>
<td>No</td>
<td>Python code implementing the function</td>
</tr>
<tr>
<td><code>parameters</code></td>
<td>Array</td>
<td>No</td>
<td>Parameters for the function</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">functions:
  is_valid_order:
    type: &quot;predicate&quot;
    code: |
      if value is None:
        return False

      if &quot;orderId&quot; not in value:
        return False

      if &quot;items&quot; not in value or not value[&quot;items&quot;]:
        return False

      return True

  enrich_order:
    type: &quot;mapper&quot;
    code: |
      return {
        &quot;order_id&quot;: value.get(&quot;orderId&quot;),
        &quot;customer_id&quot;: value.get(&quot;customerId&quot;),
        &quot;items&quot;: value.get(&quot;items&quot;, []),
        &quot;total&quot;: sum(item.get(&quot;price&quot;, 0) * item.get(&quot;quantity&quot;, 0) for item in value.get(&quot;items&quot;, [])),
        &quot;timestamp&quot;: value.get(&quot;timestamp&quot;, int(time.time() * 1000))
      }
</code></pre>
<h2 id="pipeline-definitions">Pipeline Definitions</h2>
<p>Pipelines define the flow of data through the application.</p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>from</code></td>
<td>String/Array</td>
<td>Yes</td>
<td>The source stream(s) or table(s)</td>
</tr>
<tr>
<td><code>via</code></td>
<td>Array</td>
<td>No</td>
<td>The operations to apply to the data</td>
</tr>
<tr>
<td><code>to</code></td>
<td>String/Array</td>
<td>Yes</td>
<td>The destination stream(s)</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">pipelines:
  process_orders:
    from: &quot;orders&quot;
    via:
      - type: &quot;filter&quot;
        if:
          code: &quot;is_valid_order(key, value)&quot;
      - type: &quot;mapValues&quot;
        mapper:
          code: &quot;enrich_order(key, value)&quot;
      - type: &quot;peek&quot;
        forEach:
          code: |
            log.info(&quot;Processing order: {}&quot;, value.get(&quot;order_id&quot;))
    to: &quot;processed_orders&quot;
</code></pre>
<h2 id="application-configuration">Application Configuration</h2>
<p>The <code>config</code> section contains application-level configuration options.</p>
<h3 id="kafka-configuration_1">Kafka Configuration</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>bootstrap.servers</code></td>
<td>String</td>
<td>Yes</td>
<td>Comma-separated list of Kafka broker addresses</td>
</tr>
<tr>
<td><code>application.id</code></td>
<td>String</td>
<td>Yes</td>
<td>The unique identifier for the Kafka Streams application</td>
</tr>
<tr>
<td><code>client.id</code></td>
<td>String</td>
<td>No</td>
<td>The client identifier</td>
</tr>
<tr>
<td><code>auto.offset.reset</code></td>
<td>String</td>
<td>No</td>
<td>Default offset reset policy (<code>earliest</code>, <code>latest</code>, <code>none</code>)</td>
</tr>
<tr>
<td><code>schema.registry.url</code></td>
<td>String</td>
<td>No</td>
<td>The URL of the schema registry</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">config:
  kafka:
    bootstrap.servers: &quot;kafka1:9092,kafka2:9092,kafka3:9092&quot;
    application.id: &quot;order-processing-app&quot;
    client.id: &quot;order-processing-client&quot;
    auto.offset.reset: &quot;earliest&quot;
    schema.registry.url: &quot;http://schema-registry:8081&quot;
</code></pre>
<h3 id="state-store-configuration">State Store Configuration</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>state.dir</code></td>
<td>String</td>
<td>No</td>
<td>The directory for state stores</td>
</tr>
<tr>
<td><code>cache.max.bytes.buffering</code></td>
<td>Integer</td>
<td>No</td>
<td>The maximum size of the cache in bytes</td>
</tr>
<tr>
<td><code>commit.interval.ms</code></td>
<td>Integer</td>
<td>No</td>
<td>The commit interval in milliseconds</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">config:
  state:
    state.dir: &quot;/tmp/kafka-streams&quot;
    cache.max.bytes.buffering: 10485760  # 10 MB
    commit.interval.ms: 30000  # 30 seconds
</code></pre>
<h3 id="logging-configuration">Logging Configuration</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>level</code></td>
<td>String</td>
<td>No</td>
<td>The log level (<code>DEBUG</code>, <code>INFO</code>, <code>WARN</code>, <code>ERROR</code>)</td>
</tr>
<tr>
<td><code>file</code></td>
<td>String</td>
<td>No</td>
<td>The log file path</td>
</tr>
<tr>
<td><code>pattern</code></td>
<td>String</td>
<td>No</td>
<td>The log pattern</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">config:
  logging:
    level: &quot;INFO&quot;
    file: &quot;/var/log/ksml/application.log&quot;
    pattern: &quot;%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n&quot;
</code></pre>
<h3 id="metrics-configuration">Metrics Configuration</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>reporters</code></td>
<td>Array</td>
<td>No</td>
<td>The metrics reporters to use</td>
</tr>
<tr>
<td><code>interval.ms</code></td>
<td>Integer</td>
<td>No</td>
<td>The metrics reporting interval in milliseconds</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">config:
  metrics:
    reporters:
      - type: &quot;jmx&quot;
      - type: &quot;prometheus&quot;
        port: 8080
    interval.ms: 60000  # 60 seconds
</code></pre>
<h3 id="security-configuration">Security Configuration</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>protocol</code></td>
<td>String</td>
<td>No</td>
<td>The security protocol (<code>PLAINTEXT</code>, <code>SSL</code>, <code>SASL_PLAINTEXT</code>, <code>SASL_SSL</code>)</td>
</tr>
<tr>
<td><code>ssl</code></td>
<td>Object</td>
<td>No</td>
<td>SSL configuration</td>
</tr>
<tr>
<td><code>sasl</code></td>
<td>Object</td>
<td>No</td>
<td>SASL configuration</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">config:
  security:
    protocol: &quot;SASL_SSL&quot;
    ssl:
      truststore.location: &quot;/etc/kafka/ssl/kafka.truststore.jks&quot;
      truststore.password: &quot;${TRUSTSTORE_PASSWORD}&quot;
    sasl:
      mechanism: &quot;PLAIN&quot;
      jaas.config: &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;${KAFKA_USERNAME}\&quot; password=\&quot;${KAFKA_PASSWORD}\&quot;;&quot;
</code></pre>
<h3 id="environment-variables">Environment Variables</h3>
<p>KSML supports environment variable substitution in configuration values.</p>
<p>Example:</p>
<pre><code class="language-yaml">config:
  kafka:
    bootstrap.servers: &quot;${KAFKA_BOOTSTRAP_SERVERS}&quot;
    application.id: &quot;${APPLICATION_ID:-order-processing-app}&quot;  # Default value if not set
</code></pre>
<h2 id="advanced-configuration">Advanced Configuration</h2>
<h3 id="custom-serializers-and-deserializers">Custom Serializers and Deserializers</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>key.serializer</code></td>
<td>String</td>
<td>No</td>
<td>The key serializer class</td>
</tr>
<tr>
<td><code>key.deserializer</code></td>
<td>String</td>
<td>No</td>
<td>The key deserializer class</td>
</tr>
<tr>
<td><code>value.serializer</code></td>
<td>String</td>
<td>No</td>
<td>The value serializer class</td>
</tr>
<tr>
<td><code>value.deserializer</code></td>
<td>String</td>
<td>No</td>
<td>The value deserializer class</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">config:
  serialization:
    key.serializer: &quot;org.apache.kafka.common.serialization.StringSerializer&quot;
    key.deserializer: &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;
    value.serializer: &quot;io.confluent.kafka.serializers.KafkaAvroSerializer&quot;
    value.deserializer: &quot;io.confluent.kafka.serializers.KafkaAvroDeserializer&quot;
</code></pre>
<h3 id="custom-state-stores">Custom State Stores</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>name</code></td>
<td>String</td>
<td>Yes</td>
<td>The name of the state store</td>
</tr>
<tr>
<td><code>type</code></td>
<td>String</td>
<td>Yes</td>
<td>The type of state store (<code>persistent</code>, <code>in-memory</code>)</td>
</tr>
<tr>
<td><code>config</code></td>
<td>Object</td>
<td>No</td>
<td>Additional configuration for the state store</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">config:
  stateStores:
    - name: &quot;order-store&quot;
      type: &quot;persistent&quot;
      config:
        retention.ms: 604800000  # 7 days
        cleanup.policy: &quot;compact&quot;
</code></pre>
<h3 id="processing-guarantees">Processing Guarantees</h3>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>processing.guarantee</code></td>
<td>String</td>
<td>No</td>
<td>The processing guarantee (<code>at_least_once</code>, <code>exactly_once</code>, <code>exactly_once_v2</code>)</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<pre><code class="language-yaml">config:
  processing:
    processing.guarantee: &quot;exactly_once_v2&quot;
</code></pre>
<h2 id="best-practices">Best Practices</h2>
<ol>
<li><strong>Use environment variables for sensitive information</strong>: Avoid hardcoding sensitive information like passwords</li>
<li><strong>Set appropriate retention periods for state stores</strong>: Consider your application's requirements and available disk
   space</li>
<li><strong>Configure appropriate commit intervals</strong>: Balance between throughput and recovery time</li>
<li><strong>Use descriptive names for streams, tables, and functions</strong>: Make your KSML definitions self-documenting</li>
<li><strong>Set appropriate log levels</strong>: Use <code>INFO</code> for production and <code>DEBUG</code> for development</li>
<li><strong>Monitor your application</strong>: Configure metrics reporters to track your application's performance</li>
<li><strong>Use exactly-once processing guarantees for critical applications</strong>: Ensure data integrity for important
   applications</li>
</ol>
<h2 id="related-topics">Related Topics</h2>
<ul>
<li><a href="../language-reference/">KSML Language Reference</a></li>
<li><a href="../operations-reference/">Operations Reference</a></li>
<li><a href="../functions-reference/">Functions Reference</a></li>
<li><a href="../data-types-reference/">Data Types Reference</a></li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js"></script>
        <script src="../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
